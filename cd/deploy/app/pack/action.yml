##
# (c) 2021-2025
#     Cloud Ops Works LLC - https://cloudops.works/
#     Find us on:
#       GitHub: https://github.com/cloudopsworks
#       WebSite: https://cloudops.works
#     Distributed Under Apache v2.0 License
#
name: Zip Packaging for Uploading
author:  cloudopsworks
description: Zip Packaging for Uploading
inputs:
  source_path:
    description: 'The path to the source code'
    required: false
    default: 'source'
  blueprint_path:
    description: 'The path to the blueprint'
    required: false
    default: 'bp'
  cloud:
    description: 'The target cloud'
    required: true
  cloud_type:
    description: 'The target cloud type'
    required: true
  aws_region:
    description: 'The AWS region'
    required: true
  aws_access_key_id:
    description: 'AWS Access Key ID'
    required: true
  aws_secret_access_key:
    description: 'AWS Secret Access Key'
    required: true
  aws_sts_role_arn:
    description: 'AWS STS Role ARN'
    required: true
  release_name:
    description: 'The release name'
    required: true
  release_version:
    description: 'The release version'
    required: true
  project_key:
    description: 'The package name'
    required: true
  environment:
    description: 'The environment'
    required: true
  observability_enabled:
    description: 'The observability flag'
    required: false
    default: 'false'
  observability_agent:
    description: 'The observability agent'
    required: false
    default: 'xray'

outputs:
  dest_zip_path:
    description: 'Destination ZIP path'
    value: ${{ steps.dest_zip.outputs.result }}

runs:
  using: 'composite'
  steps:
    - name: Get Bucket Config
      id: bucket_config
      uses: ./bp/cd/deploy/app/pack/bucket-config
      with:
        blueprint_path: ${{ inputs.blueprint_path }}
        cloud: ${{ inputs.cloud }}
        cloud_type: ${{ inputs.cloud_type }}
        environment: ${{ inputs.environment }}

    - name: Stack Retrieval
      id: stack
      uses: ./bp/cd/deploy/app/pack/stack-config
      with:
        blueprint_path: ${{ inputs.blueprint_path }}
        cloud: ${{ inputs.cloud }}
        cloud_type: ${{ inputs.cloud_type }}
        environment: ${{ inputs.environment }}

    - name: Create temp_dir
      id: temp_dir
      shell: bash
      run: |
        temp_dir=$(mktemp -d)
        echo "result=$temp_dir" >> $GITHUB_OUTPUT

#    - name: DEBUG
#      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}
#      shell: bash
#      run: |
#        pwd
#        ls -ltR
#
    - name: Copy NodeJS Application Release
      working-directory: ${{ steps.temp_dir.outputs.result }}
      if: ${{ steps.stack.outputs.node_stack == 'true' }}
      shell: bash
      run: |
        tar -xf ${{ github.workspace }}/${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release/*.tar 

    - name: Copy .env into for NodeJS
      if: ${{ steps.stack.outputs.node_stack == 'true' }}
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}
      shell: bash
      run: |
        [ -f values/.env ] && cp -pf values/.env ${{ steps.temp_dir.outputs.result }}

    - name: Copy Python Application Release
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release
      if: ${{ steps.stack.outputs.python_stack == 'true' }}
      shell: bash
      run: |
        cp -pfr . ${{ steps.temp_dir.outputs.result }}/
        if [ -f python-dependencies.tar ]; then
          echo "Extracting Python dependencies as python-dependencies.tar has been found."
          tar -xf python-dependencies.tar -C ${{ steps.temp_dir.outputs.result }}
          rm -f python-dependencies.tar
        fi

    - name: Copy .Net Application Release
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release
      if: ${{ steps.stack.outputs.dotnet_stack == 'true' }}
      shell: bash
      run: |
        cp -pfr ./PublishRelease/ ${{ steps.temp_dir.outputs.result }}/

    - name: Copy GoLang/Rust Application Release
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release
      if: ${{ steps.stack.outputs.go_stack == 'true' }}
      shell: bash
      run: |
        cp -pfr ./bin/ ${{ steps.temp_dir.outputs.result }}/

    - name: Copy Java Application Release
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release/target
      if: ${{ steps.stack.outputs.java_stack == 'true' }}
      shell: bash
      run: |
        cp -p ./*.jar ${{ steps.temp_dir.outputs.result }}/app.jar

    # Observability
    - name: Generate observability artifacts for java
      if: ${{ inputs.observability_enabled == 'true' && steps.stack.outputs.java_stack == 'true' }}
      working-directory: ${{ steps.temp_dir.outputs.result }}
      shell: bash
      id: java_apm
      run: |
        echo "::group::Generate observability artifacts for java"
        case "${{ inputs.observability_agent }}" in
          xray)
            curl -Lo xray-agent.zip https://github.com/aws/aws-xray-java-agent/releases/latest/download/xray-agent.zip
            unzip xray-agent.zip
            rm xray-agent.zip
            echo "result=-javaagent:./disco/disco-java-agent.jar=pluginPath=./disco/disco-plugins -Dcom.amazonaws.xray.strategy.tracingName=${{ inputs.project_key }}" >> $GITHUB_OUTPUT
            ;;
          datadog)
            curl -Lo dd-java-agent.jar 'https://dtdg.co/latest-java-tracer'
            echo "result=-javaagent:./dd-java-agent.jar -Ddd.env=${{ inputs.environment }} -Ddd.service=${{ inputs.release_name }} -Ddd.version=${{ inputs.release_version }}" >> $GITHUB_OUTPUT
            ;;
        esac
        echo "::endgroup::"
    # Observability

    - name: Copy Application Release
      if: ${{ steps.stack.outputs.java_stack != 'true' && steps.stack.outputs.node_stack != 'true' && steps.stack.outputs.python_stack != 'true' }}
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release
      shell: bash
      run: |
        cp -vpr ./* ${{ steps.temp_dir.outputs.result }}

    - name: Copy values/ into temp dir
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/values
      shell: bash
      run: |
        cp -vpfR . ${{ steps.temp_dir.outputs.result }}

    - name: Generate Procfile for ElasticBeanstalk
      if: ${{ inputs.cloud_type == 'beanstalk' }}
      uses: ./bp/cd/deploy/app/pack/procfile
      with:
        temp_dir: ${{ steps.temp_dir.outputs.result }}
        java_stack: ${{ steps.stack.outputs.java_stack }}
        node_stack: ${{ steps.stack.outputs.node_stack }}
        python_stack: ${{ steps.stack.outputs.python_stack }}
        java_apm: ${{ steps.java_apm.outputs.result }}
        node_apm: ${{ steps.node_apm.outputs.result }}
        python_apm: ${{ steps.python_apm.outputs.result }}

    ## Generate ZIP and push to bucket
    - name: Generate ZIP and report filename
      working-directory: ${{ steps.temp_dir.outputs.result }}
      id: dest_zip
      shell: bash
      run: |
        tmp_dir=$(mktemp -d)
        zip -1 -q -y -r $tmp_dir/app.zip .
        echo "result=$tmp_dir/app.zip" >> $GITHUB_OUTPUT

    - name: Temporary STS Assume Role
      id: sts
      shell: bash
      run: |
        TEMP_ROLE=$(aws sts assume-role --role-arn "${ASSUME_ROLE_ARN}" --role-session-name "${ROLE_SESSION_NAME:-AssumingRole}")
        echo "aws_access_key_id=$(echo "${TEMP_ROLE}" | jq -r '.Credentials.AccessKeyId')" >> $GITHUB_OUTPUT
        echo "aws_secret_access_key=$(echo "${TEMP_ROLE}" | jq -r '.Credentials.SecretAccessKey')" >> $GITHUB_OUTPUT
        echo "aws_session_token=$(echo "${TEMP_ROLE}" | jq -r '.Credentials.SessionToken')" >> $GITHUB_OUTPUT
      env:
        AWS_ACCESS_KEY_ID: ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        ASSUME_ROLE_ARN: ${{ inputs.aws_sts_role_arn }}
        ROLE_SESSION_NAME: s3-upload-pipeline
        AWS_REGION: ${{ inputs.aws_region }}

    - name: Upload to S3
      working-directory: ${{ steps.temp_dir.outputs.result }}
      shell: bash
      run: |
        echo "::group::Uploading to S3"
        aws s3 cp ${{ steps.dest_zip.outputs.result }} s3://${{ steps.bucket_config.outputs.versions_bucket }}/${{ steps.bucket_config.outputs.bucket_path }}
        echo "::endgroup::"
      env:
        AWS_ACCESS_KEY_ID: ${{ steps.sts.outputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ steps.sts.outputs.aws_secret_access_key }}
        AWS_SESSION_TOKEN: ${{ steps.sts.outputs.aws_session_token }}
        AWS_REGION: ${{ inputs.aws_region }}