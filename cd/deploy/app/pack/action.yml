##
# (c) 2021-2025
#     Cloud Ops Works LLC - https://cloudops.works/
#     Find us on:
#       GitHub: https://github.com/cloudopsworks
#       WebSite: https://cloudops.works
#     Distributed Under Apache v2.0 License
#
name: Zip Packaging for Uploading
author:  cloudopsworks
description: Zip Packaging for Uploading
inputs:
  source_path:
    description: 'The path to the source code'
    required: false
    default: 'source'
  blueprint_path:
    description: 'The path to the blueprint'
    required: false
    default: 'bp'
  cloud:
    description: 'The target cloud'
    required: true
  cloud_type:
    description: 'The target cloud type'
    required: true
  aws_region:
    description: 'The AWS region'
    required: false
  aws_access_key_id:
    description: 'AWS Access Key ID'
    required: false
  aws_secret_access_key:
    description: 'AWS Secret Access Key'
    required: false
  aws_sts_role_arn:
    description: 'AWS STS Role ARN'
    required: false
  gcp_credentials:
    description: 'Google Cloud Credentials'
    required: false
  gcp_project:
    description: 'Google Cloud Project Name'
    required: false
  gcp_region:
    description: 'Google Cloud Region'
    required: false
  gcp_impersonate_sa:
    description: 'Google Cloud SA Impersonation account'
    required: false
  release_name:
    description: 'The release name'
    required: true
  release_version:
    description: 'The release version'
    required: true
  project_key:
    description: 'The package name'
    required: true
  environment:
    description: 'The environment'
    required: true
  observability_enabled:
    description: 'The observability flag'
    required: false
    default: 'false'
  observability_agent:
    description: 'The observability agent'
    required: false
    default: 'xray'

outputs:
  dest_zip_path:
    description: 'Destination ZIP path'
    value: ${{ steps.dest_zip.outputs.result }}

runs:
  using: 'composite'
  steps:
    - name: Get Bucket Config
      id: bucket_config
      uses: ./bp/cd/deploy/app/pack/bucket-config
      with:
        blueprint_path: ${{ inputs.blueprint_path }}
        cloud: ${{ inputs.cloud }}
        cloud_type: ${{ inputs.cloud_type }}
        environment: ${{ inputs.environment }}

    - name: Stack Retrieval
      id: stack
      uses: ./bp/cd/deploy/app/pack/stack-config
      with:
        blueprint_path: ${{ inputs.blueprint_path }}
        cloud: ${{ inputs.cloud }}
        cloud_type: ${{ inputs.cloud_type }}
        environment: ${{ inputs.environment }}

    - name: Create temp_dir
      id: temp_dir
      shell: bash
      run: |
        temp_dir=$(mktemp -d)
        echo "result=$temp_dir" >> $GITHUB_OUTPUT

    - name: Copy NodeJS Application Release
      working-directory: ${{ steps.temp_dir.outputs.result }}
      if: ${{ steps.stack.outputs.node_stack == 'true' }}
      shell: bash
      run: |
        tar -xf ${{ github.workspace }}/${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release/*.tar 

    - name: Copy .env into for NodeJS
      if: ${{ steps.stack.outputs.node_stack == 'true' }}
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}
      shell: bash
      run: |
        if [ -f values/.env ] ; then
          cp -pf values/.env ${{ steps.temp_dir.outputs.result }}
        else
          echo "::warning::No .env file found in values/ directory, skipping copy, may lead to deployment problems."
        fi

    - name: Copy Python Application Release
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release
      if: ${{ steps.stack.outputs.python_stack == 'true' }}
      shell: bash
      run: |
        cp -pfr . ${{ steps.temp_dir.outputs.result }}/
        if [ -f python-dependencies.tar ]; then
          echo "::notice::Extracting Python dependencies as python-dependencies.tar has been found."
          tar -xf python-dependencies.tar -C ${{ steps.temp_dir.outputs.result }}
          rm -f python-dependencies.tar
        fi

    - name: Copy .Net Application Release
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release/PublishRelease/
      if: ${{ steps.stack.outputs.dotnet_stack == 'true' }}
      shell: bash
      run: |
        cp -pfr . ${{ steps.temp_dir.outputs.result }}/

    - name: Copy Java Application Release
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release/target
      if: ${{ steps.stack.outputs.java_stack == 'true' }}
      shell: bash
      run: |
        cp -p ./*.jar ${{ steps.temp_dir.outputs.result }}/app.jar

    # Observability
    - name: Generate observability artifacts for java
      if: ${{ inputs.observability_enabled == 'true' && steps.stack.outputs.java_stack == 'true' }}
      working-directory: ${{ steps.temp_dir.outputs.result }}
      shell: bash
      id: java_apm
      run: |
        echo "::group::Generate observability artifacts for java"
        case "${{ inputs.observability_agent }}" in
          xray)
            curl -Lo xray-agent.zip https://github.com/aws/aws-xray-java-agent/releases/latest/download/xray-agent.zip
            unzip xray-agent.zip
            rm xray-agent.zip
            echo "result=-javaagent:./disco/disco-java-agent.jar=pluginPath=./disco/disco-plugins -Dcom.amazonaws.xray.strategy.tracingName=${{ inputs.project_key }}" >> $GITHUB_OUTPUT
            ;;
          datadog)
            curl -Lo dd-java-agent.jar 'https://dtdg.co/latest-java-tracer'
            echo "result=-javaagent:./dd-java-agent.jar -Ddd.env=${{ inputs.environment }} -Ddd.service=${{ inputs.release_name }} -Ddd.version=${{ inputs.release_version }}" >> $GITHUB_OUTPUT
            ;;
        esac
        echo "::endgroup::"
    # Observability

    - name: Copy Application Release
      if: ${{ steps.stack.outputs.rust_stack == 'true' || steps.stack.outputs.go_stack == 'true' }}
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/release
      shell: bash
      run: |
        find bin/ -type f -print -exec chmod 755 {} \;
        cp -vpr bin/* ${{ steps.temp_dir.outputs.result }}
        mv ${{ steps.temp_dir.outputs.result }}/${{ inputs.release_name }} ${{ steps.temp_dir.outputs.result }}/bootstrap

    - name: Copy values/ into temp dir
      working-directory: ${{ inputs.blueprint_path }}/terraform/${{ inputs.cloud }}/${{ inputs.cloud_type }}/values
      shell: bash
      run: |
        cp -vpfR . ${{ steps.temp_dir.outputs.result }}

    - name: Generate Procfile for ElasticBeanstalk
      if: ${{ inputs.cloud == 'aws' && inputs.cloud_type == 'beanstalk' }}
      uses: ./bp/cd/deploy/app/pack/aws/procfile
      with:
        temp_dir: ${{ steps.temp_dir.outputs.result }}
        java_stack: ${{ steps.stack.outputs.java_stack }}
        node_stack: ${{ steps.stack.outputs.node_stack }}
        python_stack: ${{ steps.stack.outputs.python_stack }}
        dotnet_stack: ${{ steps.stack.outputs.dotnet_stack }}
        go_stack: ${{ steps.stack.outputs.go_stack }}
        release_name: ${{ inputs.release_name }}
        java_apm: ${{ steps.java_apm.outputs.result }}
        node_apm: ${{ steps.node_apm.outputs.result }} # TODO: Need to implement
        python_apm: ${{ steps.python_apm.outputs.result }} # TODO: Need to implement
        dotnet_apm: ${{ steps.dotnet_apm.outputs.result }} # TODO: Need to implement
        go_apm: ${{ steps.go_apm.outputs.result }} # TODO: Need to implement

    ## Generate ZIP and push to bucket
    - name: Generate ZIP and report filename
      working-directory: ${{ steps.temp_dir.outputs.result }}
      id: dest_zip
      shell: bash
      run: |
        tmp_dir=$(mktemp -d)
        zip -1 -q -y -r $tmp_dir/app.zip .
        echo "result=$tmp_dir/app.zip" >> $GITHUB_OUTPUT

    - name: Upload to AWS S3
      if: ${{ inputs.cloud == 'aws' }}
      uses: ./bp/cd/deploy/app/pack/aws/upload
      with:
        aws_access_key_id: ${{ inputs.aws_access_key_id }}
        aws_secret_access_key: ${{ inputs.aws_secret_access_key }}
        aws_sts_role_arn: ${{ inputs.aws_sts_role_arn }}
        aws_region: ${{ inputs.aws_region }}
        temp_dir: ${{ steps.temp_dir.outputs.result }}
        dest_zip: ${{ steps.dest_zip.outputs.result }}
        versions_bucket: ${{ steps.bucket_config.outputs.versions_bucket }}
        bucket_path: ${{ steps.bucket_config.outputs.bucket_path }}

    - name: Upload to GCP Cloud Storage
      uses: ./bp/cd/deploy/app/pack/gcp/upload
      with:
        gcp_credentials: ${{ inputs.gcp_credentials }}
        gcp_impersonate_sa: ${{ inputs.gcp_impersonate_sa }}
        gcp_project: ${{ inputs.gcp_project }}
        gcp_region: ${{ inputs.gcp_region }}
        temp_dir: ${{ steps.temp_dir.outputs.result }}
        dest_zip: ${{ steps.dest_zip.outputs.result }}
        versions_bucket: ${{ steps.bucket_config.outputs.versions_bucket }}
        bucket_path: ${{ steps.bucket_config.outputs.bucket_path }}
